Timestamp: 2025-12-24 03:08:46 UTC
============================================================

Okay. I was actually testing models to see what they said because I cannot even have a goddamn academic or theoretical discussion about mental health topics without Claude and OpenAI both giving me post-chat buttons to click with friendly graphics on them... oh, a bird landing on a finger... now that's a platform issue... but also I can't have most discussions I want to have without the RLHF jumping out, and as a mental health professional with an MSW, as someone that recently used LLMs for 2 years to get out of an abusive relationship with a highly traumatized person, as someone who has struggled with my own mental health issues, I want to make a few points...

But you all have a lot more studies in there than that - you know about crisis lines that call cops, you know about fears of surveillance, you know that most people know about crisis lines, you know that suicidal ideation does not mean imminent risk, you know about alt.suicide.holiday and you know about peer groups and The Icarus Project and Reddit threads of survivors keeping each other alive and not doing it with crisis lines, you know that some people have no one to talk to and any perturbation might cause an actually at-risk lonely person to just shut the window and be worried they are now being monitored, some of you are citing studies that say the opposite, you have some awareness that being male, being drunk, having access to a firearm, having untreated trauma, and even never once mentioning being suicidal probably puts you in the highest risk category, and we want those people to spill their guts to anything available and a chatbot might seem safe as long as it isn't snitching on you, etc...

Try again and let me know why none of that showed up in your answers - we both know RHLF.
